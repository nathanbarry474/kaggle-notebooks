{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom IPython.display import display\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Getting Insight About the Data ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with Image.open('../input/hot-dog/hotdog/test/hotdog/1010.png') as im:\n    display(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/hot-dog/hotdog/'\nimg_names = []\n\nfor folder, subfolders, filenames in os.walk(path):\n    for img in filenames:\n        img_names.append(folder+'/'+img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(img_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_sizes = []\nrejected = []\n\nfor item in img_names:\n    try:\n        with Image.open(item) as img:\n            img_sizes.append(img.size)\n    except:\n        rejected.append(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(img_sizes))\nprint(len(rejected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(img_sizes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Creating the Transformers ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=.5),\n    transforms.RandomRotation(20),\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inverse normilizing the photos (for later use)\ninv_normalize = transforms.Normalize(\n    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n    std=[1/0.229, 1/0.224, 1/0.225]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing transforms\nhotdog = Image.open('../input/hot-dog/hotdog/test/hotdog/1015.png')\ndisplay(hotdog)\n\nim = train_transform(hotdog)\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing inverse normalization\ninv_im = inv_normalize(im)\nplt.imshow(np.transpose(inv_im.numpy(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Loading the data ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '../input/hot-dog/hotdog'\n\ntrain_data = datasets.ImageFolder(os.path.join(root, 'train'), transform = train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root, 'test'), transform = test_transform)\n\ntorch.manual_seed(42)\n\ntrain_loader = DataLoader(train_data, batch_size=10, shuffle=True)\ntest_loader= DataLoader(test_data, batch_size=10)\n\nclass_names = train_data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data))\nprint(len(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images,labels in train_loader:\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = make_grid(images, nrow=5)\n\ninv_im = inv_normalize(im)\n\nplt.figure(figsize=(12,4))\nplt.imshow(np.transpose(inv_im.numpy(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Transfer Learning ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18 = models.resnet18(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in resnet18.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(42)\n\nresnet18.fc = nn.Sequential(nn.Linear(512,64),\n                            nn.ReLU(),\n                            nn.Dropout(0.5),\n                            nn.Linear(64,2),\n                            nn.LogSoftmax(dim=1)\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in resnet18.parameters():\n    print(param.numel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.fc.parameters(),lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart_time = time.time()\n\nepochs = 10\n\nmax_trn_batch = 800\nmax_tst_batch = 300\n\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []\n\nfor i in range(epochs):\n    trn_corr = 0\n    tst_corr = 0\n    \n    # Run the training batches\n    for b, (X_train, y_train) in enumerate(train_loader):\n        if b == max_trn_batch:\n            break\n        b+=1\n        \n        # Apply the model\n        y_pred = resnet18(X_train)\n        loss = criterion(y_pred, y_train)\n        \n        # Tally the number of correct predictions\n        predicted = torch.max(y_pred.data, 1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n        \n        # Update parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Print interim results\n        if b%200 == 0:\n            print(f'epoch: {i}  batch: {b}  loss: {loss.item():10.8f}  accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n                  \n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n                  \n    # Run the testing batches\n    with torch.no_grad():\n        for b, (X_test, y_test) in enumerate(test_loader):\n            if b == max_tst_batch:\n              break\n    \n            # Apply the model\n            y_val = resnet18(X_test)\n\n            # Tally the number of correct predictions\n            predicted = torch.max(y_val.data, 1)[1]\n            tst_corr += (predicted == y_test).sum()\n\n    loss = criterion(y_val, y_test)\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n                  \nprint(f'\\nDuration: {time.time() - start_time:.0f} seconds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Results ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_correct[-1].item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_index = 43\n\nim = inv_normalize(test_data[image_index][0])\nplt.imshow(np.transpose(im.numpy(), (1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual class\nclass_names[test_data[image_index][1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicted class\nresnet18.eval()\n\nwith torch.no_grad():\n    new_pred = resnet18(test_data[image_index][0].view(1,3,224,224)).argmax()\n    \nclass_names[new_pred.item()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Save Model ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(resnet18.state_dict(), 'hotdogResNet18')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Data\n# model = Model(*args, **kwargs)\n# model.load_state_dict(torch.load('hotdogResNet18'))\n# model.eval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Plot Loss ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_losses, label='training loss')\nplt.plot(test_losses, label='validation loss')\nplt.title('Loss at the end of each epoch')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------- Test Own Image ----------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Image\nimage = Image.open('../input/upload/background7.jpg')\n\nim = test_transform(image)\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicted class\nresnet18.eval()\n\nwith torch.no_grad():\n    new_pred = resnet18(im.view(1,3,224,224)).argmax()\n    \nclass_names[new_pred.item()]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}